{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute `huggingface-cli delete-cache` in the terminal to select which models you want to clear from the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panag\\Desktop\\captonomy-mle\\.venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import helpers\n",
    "from helpers import Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panag\\Desktop\\captonomy-mle\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the papers and encode them into embeddings\n",
    "\n",
    "with open('papers.pkl', 'rb') as f:\n",
    "    papers: list[Paper] = pickle.load(f)\n",
    "\n",
    "papers_text = [f'Title: {paper.title} \\n Abstract: {paper.abstract}' for paper in papers]\n",
    "\n",
    "papers_emb = model.encode(papers_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the category of each paper\n",
    "\n",
    "categories_emb = model.encode(helpers.categories)\n",
    "\n",
    "similarities = model.similarity(papers_emb, categories_emb)\n",
    "\n",
    "predictions = list(map(lambda index: helpers.categories[index], similarities.argmax(dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions\n",
    "\n",
    "helpers.save_to_csv(papers, predictions, 'similarity-preds.csv')\n",
    "\n",
    "helpers.save_to_json(papers, predictions, 'similarity-preds.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the categories and predict the category of each paper\n",
    "\n",
    "extended_categories = [\n",
    "    'Tables are structured representations of data organized in rows and columns, often used to present numerical information, comparisons, and relationships clearly and efficiently.', \n",
    "    'Classification is the task of assigning predefined categories to text documents based on their content, enabling systematic organization and retrieval of information.', \n",
    "    'Key Information Extraction is the automatic identification and extraction of significant entities and relevant data from unstructured texts, facilitating efficient access to critical information and enhancing data organization.',\n",
    "    'Optical Character Recognition is the technology used to convert different types of documents, such as scanned paper documents and images, into editable and searchable data by recognizing and extracting printed or handwritten text.', \n",
    "    'Datasets are ollections of structured or unstructured data organized for analysis and research purposes, often used in machine learning and statistical modeling to train and evaluate algorithms.', \n",
    "    'Document Layout Understanding is the process of analyzing and interpreting the structural layout of documents to extract meaningful information about the arrangement and organization of content, including text, images, tables, and other elements.', \n",
    "    'Others are any additional tasks or methodologies related to document processing and information extraction that do not fit into the predefined categories, encompassing a variety of techniques and applications.'\n",
    "]\n",
    "\n",
    "extended_categories_emb = model.encode(extended_categories)\n",
    "\n",
    "similarities_extended = model.similarity(papers_emb, extended_categories_emb)\n",
    "\n",
    "predictions_extended = list(map(lambda index: helpers.categories[index], similarities_extended.argmax(dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions\n",
    "\n",
    "helpers.save_to_csv(papers, predictions_extended, 'similarity-preds-ext.csv')\n",
    "\n",
    "helpers.save_to_json(papers, predictions_extended, 'similarity-preds-ext.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
