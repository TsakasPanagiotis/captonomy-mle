{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import zipfile\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pypdf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Paper:\n",
    "    filename: str\n",
    "    title_authors_info: str = ''\n",
    "    abstract: str = ''\n",
    "    keywords: str = ''\n",
    "    introduction: str = ''\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'----------\\n filename \\n----------\\n\\n {self.filename}' + \\\n",
    "               f'\\n\\n----------\\n title_authors_info \\n----------\\n\\n {self.title_authors_info}' + \\\n",
    "               f'\\n\\n----------\\n abstract \\n----------\\n\\n {self.abstract}' + \\\n",
    "               f'\\n\\n----------\\n keywords \\n----------\\n\\n {self.keywords}' + \\\n",
    "               f'\\n\\n----------\\n introduction \\n----------\\n\\n {self.introduction}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [00:05<00:00, 26.71it/s]\n"
     ]
    }
   ],
   "source": [
    "zip_path = 'ml-engineer/ICDAR2024_papers.zip'\n",
    "\n",
    "papers: list[Paper] = []\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    for file_info in tqdm(zip_ref.infolist()):\n",
    "        if not file_info.is_dir() and file_info.filename.lower().endswith('.pdf'):\n",
    "            \n",
    "            paper = Paper(filename=file_info.filename)\n",
    "            \n",
    "            with zip_ref.open(paper.filename) as pdf_file:\n",
    "                pdf_reader = pypdf.PdfReader(io.BytesIO(pdf_file.read()))\n",
    "                first_page = pdf_reader.pages[0]                \n",
    "                \n",
    "                text = first_page.extract_text()\n",
    "                \n",
    "                # Split abstract only once\n",
    "                abstract_split = re.split(r'Abstract\\.?', text, maxsplit=1)\n",
    "\n",
    "                if len(abstract_split) == 1:\n",
    "                    print(f'No abstract found in {paper.filename}')\n",
    "                    continue\n",
    "\n",
    "                if len(abstract_split) == 2:\n",
    "                    paper.title_authors_info = abstract_split[0]\n",
    "                    paper.abstract = abstract_split[1]\n",
    "                    text = paper.abstract\n",
    "                \n",
    "                # Split keywords only once\n",
    "                keywords_split = re.split(r'Keywords:?', text, maxsplit=1)\n",
    "                \n",
    "                # if len(keywords_split) == 1: pass # No keywords found\n",
    "\n",
    "                if len(keywords_split) == 2:\n",
    "                    paper.abstract = keywords_split[0]\n",
    "                    paper.keywords = keywords_split[1]\n",
    "                    text = paper.keywords                \n",
    "                \n",
    "                # Split at introduction only once\n",
    "                introduction_split = re.split(r'1\\s*Introduction|Introduction', text, maxsplit=1)\n",
    "                \n",
    "                # if len(introduction_split) == 1: pass # No introduction found\n",
    "\n",
    "                if len(introduction_split) == 2:\n",
    "                    if len(keywords_split) == 1:\n",
    "                        paper.abstract = introduction_split[0]\n",
    "                        paper.introduction = introduction_split[1]\n",
    "                    if len(keywords_split) == 2:\n",
    "                        paper.keywords = introduction_split[0]\n",
    "                        paper.introduction = introduction_split[1]\n",
    "                \n",
    "                papers.append(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      " filename \n",
      "----------\n",
      "\n",
      " ICDAR2024_proceedings_pdfs/0022.pdf\n",
      "\n",
      "----------\n",
      " title_authors_info \n",
      "----------\n",
      "\n",
      " CREPE: Coordinate-Aware End-to-End\n",
      "Document Parser\n",
      "Yamato Okamoto1,2∗†[0009−0009−2153−3782],\n",
      "Youngmin Baek1,2∗‡[0000−0001−7001−4641],\n",
      "Geewook Kim1[0009 −0001−6713−3858], Ryota Nakao1,2[0009 −0001−6692−6952],\n",
      "DongHyun Kim1[0000 −0001−9033−5231], Moon Bin Yim1[0000 −0002−7272−2198],\n",
      "Seunghyun Park1[0000 −0002−8509−9163], and Bado Lee1[0000 −0003−4962−8977]\n",
      "1NAVER Cloud AI, Seongnam-si, Gyeonggi-do, Korea\n",
      "okamoto.yamato.w15@kyoto-u.jp\n",
      "{youngmin.baek, gw.kim, dong.hyun }@navercorp.com\n",
      "{moonbin.yim, seung.park, bado.lee }@navercorp.com\n",
      "2LINE WORKS, Shibuya-city, Toyko, Japan\n",
      "nakao.ryota@line-works.com\n",
      "\n",
      "\n",
      "----------\n",
      " abstract \n",
      "----------\n",
      "\n",
      "  In this study, we formulate an OCR-free sequence genera-\n",
      "tion model for visual document understanding (VDU). Our model not\n",
      "only parses text from document images but also extracts the spatial\n",
      "coordinates of the text based on the multi-head architecture. Named as\n",
      "Coordinate-awa reEnd-to-end Document Parser(CREPE) , our method\n",
      "uniquely integrates these capabilities by introducing a special token for\n",
      "OCR text, and token-triggered coordinate decoding. We also proposed\n",
      "a weakly-supervised framework for cost-efficient training, requiring only\n",
      "parsing annotations without high-cost coordinate annotations. Our ex-\n",
      "perimental evaluations demonstrate CREPE’s state-of-the-art performances\n",
      "on document parsing tasks. Beyond that, CREPE’s adaptability is fur-\n",
      "ther highlighted by its successful usage in other document understanding\n",
      "tasks such as layout analysis, document visual question answering, and\n",
      "so one. CREPE’s abilities including OCR and semantic parsing not only\n",
      "mitigate error propagation issues in existing OCR-dependent methods, it\n",
      "also significantly enhance the functionality of sequence generation mod-\n",
      "els, ushering in a new era for document understanding studies.\n",
      "\n",
      "\n",
      "----------\n",
      " keywords \n",
      "----------\n",
      "\n",
      "  Visual Document Understanding ·Document Parsing ·Doc-\n",
      "ument Information Extraction ·Optical Character Recognition ·End-to-\n",
      "End Transformer ·Weakly Supervised Learning.\n",
      "∗Equal contribution.\n",
      "†Current Affiliation: CyberAgent, Inc.\n",
      "‡Corresponding author.\n",
      "\n",
      "----------\n",
      " introduction \n",
      "----------\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for paper in papers:\n",
    "    if paper.filename == 'ICDAR2024_proceedings_pdfs/0022.pdf':\n",
    "        print(paper)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
